\begin{frame}
    \frametitle{Latent space}
    Most generative models are unsupervised Deep Learning ones which learn to generate data from the learnt, \textbf{latent representations}.

    \textbf{Latent representation} = spatially-reduced and high-level abstract representation of the target data. Usually found in the middle of an encoder-decoder architecture.
    \img{latent-space}
\end{frame}

\begin{frame}
    \frametitle{Models}
    These are some of the most common models employed in generative deep learning:
    \begin{itemize}
        \item Autoencoders.
        \item Generative Adversarial Networks (GAN).
        \item Diffusion Models.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Autoencoders}
    An \textbf{autoencoder} is made up of two parts: an encoder and a decoder, with the latent representation (called code) in the middle.
    $$\text{Encoder} \to \text{Code} \to \text{Decoder}$$
    They were used in the first DL models, and they are still used today inside the bigger models.
    \img{latent-space}
\end{frame}