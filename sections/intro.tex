\begin{frame}
    \frametitle{Goal}
    The following slides aim to provide a compact overview of the most popular \textbf{Deep Learning approaches and techniques for data generation} (often also simply called \emph{generative approaches}), both from a \emph{theoretical} and \emph{practical} standpoint.

    \begin{block}{On the task of image generation}
        While most of the examples here cover ``convolutional-flavors'' of the proposed architectures, mainly targeted towards image generation, these approaches can still be used for other generative tasks with big success (like text generation, speech synthesis, etc.)
    \end{block}

\end{frame}

\begin{frame}
    \frametitle{Structure of the document}
    For every architecture the slides present first a quick theoretical introduction and next a heavily commented Python notebook with a demonstration of the covered DL model using common datasets (like MNIST digits, MNIST fashion and CelebA).

    In the end, I propose a final series of Python notebooks which compare the generative performances of the aforementioned architectures using a dataset found ``in the wild'', while showcasing all the needed preprocessing, fixes, analyses and tuning conducted during a typical ML/DL pipeline.
\end{frame}

\begin{frame}
    \frametitle{Topics / covered architectures}
    \tableofcontents
\end{frame}