\begin{frame}
    \frametitle{Definition}
    A \textbf{Generative Adversarial Network} is a kind of neural network mainly used for generative tasks. The architecture was proposed by Ian Goodfellow in 2014.

    \textbf{Adversarial} = it is inspired from game theory. in which there are two agents who compete with each other in a \emph{zero-sum game}:
    \begin{itemize}
        \item The \textbf{generator}.
        \item The \textbf{discriminator}.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{The Generator model}
    The \textbf{generator} model learns to transform (usually) uniform noise in the latent space\footnote{Usually called $z$ space in literature} into an image which is \emph{similar} to the ones in the training set:
    $$\text{Noise} \to \text{Image (synthetic)}$$
    \img{generator}
\end{frame}

\begin{frame}
    \frametitle{The Discriminator model}
    The \textbf{discriminator} model learns to classify fake images apart from the real ones:
    $$\text{Image (either real or synthetic)} \to \; \in [0,1]$$
    \img{discriminator}
\end{frame}

\begin{frame}
    \frametitle{Full GAN architecture}
    The full architecture is then built as follows:
    \begin{enumerate}
        \item The generator builds fake images (progressively better).
        \item The discriminator discerns between fake and real images (progressively better).
    \end{enumerate}
    \img{gan}
\end{frame}

\begin{frame}
    \frametitle{Training and loss}

    \only<1>{Now we only need to establish appropriate loss functions for the two models:
    \begin{enumerate}
        \item The generator needs to maximize the discriminator classification error.
        \item The discriminator needs to minimize its own classification error.
    \end{enumerate}}

    \only<2>{We can use Binary Cross-Entropy (BCE) and backpropagation for both models:
    \begin{enumerate}
        \item The generator updates its weights through evalutation of $n$ generated fakes through the discriminator ($n$ is the batch size).
        \item Discriminator weights are updated according to the discriminator own predictions over a collection of $n$ real images and $n$ fakes ($\Rightarrow$ $2n$ evaluations in a single step).
    \end{enumerate}}

    \img{loss}
\end{frame}

\begin{frame}
    \frametitle{DCGAN and GAN}
    What has been showed until now are \textbf{Deep Convolution GANs} or \textbf{DCGANs}. 
    
    A \textbf{DCGAN} is a convolutional flavor of the GAN model, which uses features borrowed from modern convolutional neural networks and deep learning in order to attain a \emph{stable} training phase. These features are such as:
    \begin{itemize}
        \item Convolutional, batch normalization and flattening layers.
        \item Learnable downsampling / upsampling in spite of max pooling.
        \item $\sigma$ layer as the output of the discriminator.
        \item And more\dots
    \end{itemize}

    \textbf{GAN} architectures on the other hand simply introduced the two-player zero-sum game between the generator / forger and the discriminator / critic / inspector.
\end{frame}

\begin{frame}
    \frametitle{GAN issues}
    GAN has often shown great success in tasks of realistic image generation. Nevertheless, the training process is also known to be \textbf{slow} and \textbf{unstable}. Here are some of the common issues:
    \begin{itemize}
        \item Mode collapse.
        \item Lack of a proper evaluation metric.
        \item Vanishing gradient.
        \item Hard-achievable equilibrium.
        \item Low dimensional supports.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{GAN issues - Mode collapse}
    During training, \textbf{the generator is able to cheat through a repeated output pattern}. This common failure case is referred to as \textbf{mode collapse}.

    In such a case, it is said that the generator is not able to learn the real-world data distribution and thus prefers to get stuck into a low variety space.

    \img{mode_collapse}
\end{frame}

\begin{frame}
    \frametitle{GAN issues - No proper evaluation metric}
    While working with GANs \textbf{there is not a good function which is able to clearly tell us the progress of the training phase}.

    Without a good metric we cannot\dots
    \begin{itemize}
        \item \dots Estimate when do we have to stop.
        \item \dots Compare the performances of different models.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{GAN issues - Vanishing gradient}
    Assuming a perfect discriminator, we can intuitively gather that its loss is exactly $0$. When this happens, training may prove very slow.
    \imgv{GAN_vanishing_gradient}
    As we can see, the loss decreases very fast in respect to the number of epochs. Therefore, we face a crucial dilemma: \textbf{either we lose a reliable feedback loop, or we gather one at the cost of an extremely slow training of the generator model}.
\end{frame}

\begin{frame}
    \frametitle{GAN issues - Hard-achievable equilibrium}
    As GANs are an example of a game theory zero-sum game, we should ask ourselves whether we can expect the game to reach a \textbf{Nash equilibrium}: a state where every player in the game do not move as to not worsen their personal state.

    It has been shown that GAN-posed zero-sum games \textbf{may have no Nash equilibria}. Therefore, we cannot expect the network to quietly converge \emph{a priori}.
\end{frame}

\begin{frame}
    \frametitle{GAN issues - Low dimensional supports}
    Probability distributions for both $p_r$ (dataset / real images) and $p_g$ (fake images) are both concentrated in low dimensional manifolds:
    \begin{itemize}
        \item Real images representing a specific \emph{concept} have to follow many constraints and are therefore represented in a low-dimensional manifold.
        \item Fake images are generated from a relatively small patch of noises (relative to the image size) are therefore low-dimensional.
    \end{itemize}
    All together, \textbf{we need to find the intersection between two low-dimensional manifolds in a higher dimensionality space, and this is very difficult or even impossible}. In the latter, we can prove that we can always find a perfect discriminator.
\end{frame}

\begin{colab}
    Outline / contents:
    \begin{itemize}
        \item Building and training a DCGAN over the Fashion MNIST and CelebA dataset.
        \item Evaluating the generative abilities of the so-built DCGANs over the training epochs.
    \end{itemize}
\end{colab}

%\begin{frame}
%    \frametitle{Wasserstein GAN}
%    Another approach was proposed in the WGAN model. These networks are conceptually based upon the \textbf{Wasserstein distance} or \textbf{Earth Mover's Distance}. This distance measures the distance between two probability distributions as ``the energy spent to transform one distribution into another, as if it was constituted by piles of dirt''.
%    \imgv{emd}
%\end{frame}
%
%\begin{frame}
%    \frametitle{Wasserstein GAN - Pros and Cons}
%    WGANs hope to provide more stable training, but at the following expenses:
%    \begin{itemize}
%        \item Training may still be unstable.
%        \item Either slow convergence or vanishing gradients.
%    \end{itemize}
%\end{frame}
%
%\begin{frame}
%    \frametitle{ESRGAN}
%    \textbf{Enhanced Super Resolution GAN}: used for AI image upscaling.
%    \img{esrgan}
%\end{frame}

\subsection{Conditional GAN}

\begin{frame}
    \frametitle{Image translation}
    \begin{block}{Image-to-image translation}
        Translating an image into another representation, given sufficient training data.
    \end{block}

    While many problems translate well to a so-defined task, these have been historically solved through customized and hand-defined solutions.

    Using the GAN idea it is possible to establish a common framework which is able to be generalized to all use cases. \cite{pix2pix}

    \img{translation}
\end{frame}

\begin{frame}
    \frametitle{Conditional GANs}
    \img{cgan}
    A \textbf{Conditional GAN} uses the same architecture as a GAN, plus a given \emph{conditioning} (often in the form of the original image or of a one-hot encoded class label).

    \begin{block}{Conditioning}
        Feeding to the network a given slice of data so as to influence the final output.
    \end{block}
\end{frame}

%\begin{frame}
%    \frametitle{CGAN for image translation}
%    If a GAN can be formalised as $G: \textbf{z} \to Y$, a CGAN can be formalised to $G: \{X,\textbf{z}\} \to Y$ ($X$ = input image, $Y$ = generated image, $\textbf{z}$ = latent vector).
%\end{frame}

\subsection{Pix2Pix}

\begin{frame}
    \frametitle{Pix2Pix architecture}
    \textbf{Pix2Pix} \cite{pix2pix} is an architecture specifically proposed for image-to-image translation tasks. It is a CGAN where:
    \begin{itemize}
        \item The \textbf{generator} is a \textbf{U-Net} with skip connections (so low-level details are able to skip the bottleneck).
        \item The \textbf{discriminator} is a \textbf{PatchGAN} classifier.
    \end{itemize}
    \imgv{pix2pix}
\end{frame}

\begin{frame}
    \frametitle{PatchGAN}
    \textbf{PatchGAN} is a CNN proposed in \cite{pix2pix} for the discriminator part of a GAN. It tries to classify local image \emph{patches} as real or fake (in this way the discriminator penalizes errors happening with high frequency image data).

    In Pix2Pix, the \textbf{PatchGAN} discriminator receives as input the spectral concatenation of both the input and target images.
    \imgv{patchgan}
\end{frame}

\subsection{CycleGAN}